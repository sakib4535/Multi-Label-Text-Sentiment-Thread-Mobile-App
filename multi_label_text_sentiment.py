# -*- coding: utf-8 -*-
"""Multi-Label Text Sentiment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FUJGkkRM6euIwiDtXNUnqRsHXkpTDoHv

# **Multi-Label Text Sentiment Classification and Word Embedding Analysis For "Thread" Social Media Appliaction Reviews**

In this project, we delve into the world of sentiment analysis and word embedding to gain valuable insights from user-generated content in the context of the popular "Thread" social media application. With over 37,000 user reviews collected from the Google Play Store and Apple App Store, our comprehensive dataset offers a rich and diverse range of sentiments and opinions.

The primary objectives of this project are:

**Sentiment Analysis:** We aim to develop a multi-label text sentiment classification model to categorize user sentiments into positive, negative, or neutral. The analysis provides valuable insights into user satisfaction, app usability, feature preferences, and potential areas for improvement.

***Word Embedding with Word2Vec:*** Leveraging Word2Vec, we perform word embedding analysis to explore the intricacies of user language, writing styles, and expressions of sentiment. By transforming text data into dense vector representations, we enable advanced NLP tasks and extract meaningful patterns and trends.
"""

import gensim
from gensim.models import word2vec
from gensim.models.word2vec import Word2Vec
import gensim.downloader as api

from IPython.display import display
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import string
import os

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, auc
from sklearn.svm import SVC
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.multioutput import MultiOutputClassifier
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler


import spacy
from wordcloud import WordCloud

from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import WordNetLemmatizer
import nltk

nltk.download('punkt')
nltk.download('wordnet')

import warnings

# Ignore all warnings
warnings.filterwarnings("ignore")

gensim.__version__

print(list(gensim.downloader.info()['models'].keys()))

data = pd.read_csv("37000_reviews_of_thread_app.csv")

"""# New Section"""

display(data)

lemmatizer = WordNetLemmatizer()

def preprocess_text(text):

  if isinstance(text, str):

    text = ''.join([char for char in text if char not in string.punctuation and not char.isdigit()])
    text = text.lower()

    words = [lemmatizer.lemmatize(word) for word in word_tokenize(text) if word.isalpha()]
    sentences = sent_tokenize(text)

    word_count = len(words)
    sentence_count = len(sentences)

    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha()]

    return {
        'tokens': tokens,
        'lemmatized_tokens': words,
        'sentences': sentences,
        'word_count': word_count,
        'sentence_count': sentence_count
    }

data['processed_description'] = data['review_description'].apply(preprocess_text)
data['processed_title'] = data['review_title'].apply(preprocess_text)

data

display(data['processed_description'][0:10])

tokens_df = pd.DataFrame({
    'tokens_text': data['processed_description'].apply(lambda x: x['tokens'] if x is not None else []),
    'tokens_title': data['processed_title'].apply(lambda x: x['tokens'] if x is not None else [])
})

tokens_df['tokens_text']

"""# Sentiment Analysis for Tokens"""

# Create a Word2Vec model for 'tokens_text'
model_text = Word2Vec(tokens_df['tokens_text'], vector_size=100, window=5, min_count=1, sg=0, hs=0, negative=10, epochs=20)
model_text.build_vocab(tokens_df["tokens_text"])

# Train the Word2Vec models
model_text.train(tokens_df['tokens_text'], total_examples=len(tokens_df['tokens_text']), epochs=model_text.epochs)

model_text

similar_word = model_text.wv.most_similar(["good", "excellent", "great"], topn=16)

# We found that Upto the 16 entity, their vector are greater thatn .5 which indicates connectedness of thee words, Other are situtated either on the neutral ior Negative positions

similar_word

from textblob import TextBlob

def analyze_token_sentiment(token):
  analysis = TextBlob(token)
  if analysis.sentiment.polarity > 0:
    return "Positive"
  elif analysis.sentiment.polarity == 0:
    return "Neutral"
  else:
    return "Negative"

tokens_df['Sentiments'] = tokens_df['tokens_text'].apply(lambda tokens: [analyze_token_sentiment(token) for token in tokens])
print(tokens_df)

sentiments = [sentiment for sentiments_list in tokens_df['Sentiments'] for sentiment in sentiments_list]


sentiment_counts = pd.Series(sentiments).value_counts()

# Create a bar plot
plt.figure(figsize=(8, 6))
sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette="viridis")
plt.title("Sentiment Label Frequency")
plt.xlabel("Sentiment Label")
plt.ylabel("Frequency")
plt.show()

def calculate_document_vector(doc, model):
    words = [word for word in doc if word in model.wv.key_to_index]
    if words:
        word_vectors = [model.wv[word] for word in words]
        return np.mean(word_vectors, axis=0)
    else:
        return np.zeros(model.vector_size)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(tokens_df['tokens_text'], tokens_df['Sentiments'], test_size=0.2, random_state=42)

mlb = MultiLabelBinarizer()
y_train_encoded = mlb.fit_transform(y_train)
y_test_encoded = mlb.transform(y_test)

# Calculate document vectors for training and testing data
X_train_vectors = [calculate_document_vector(doc, model_text) for doc in X_train]
X_test_vectors = [calculate_document_vector(doc, model_text) for doc in X_test]

# Create and train a MultiOutputClassifier with an SVM classifier
clf = MultiOutputClassifier(SVC())
clf.fit(X_train_vectors, y_train_encoded)


y_pred_encoded = clf.predict(X_test_vectors)

accuracies = [accuracy_score(y_test_encoded[:, i], y_pred_encoded[:, i]) for i in range(len(mlb.classes_))]
mean_accuracy = sum(accuracies) / len(accuracies)

print(f"Label-wise accuracies: {accuracies}")
print(f"Mean accuracy: {mean_accuracy}")

accuracy = accuracy_score(y_test_encoded, y_pred_encoded)
print(f"Accuracy Rate: {accuracy}")

# Calculate precision, recall, and F1-score
precision = precision_score(y_test_encoded, y_pred_encoded, average='weighted')
recall = recall_score(y_test_encoded, y_pred_encoded, average='weighted')
print(f"Precision: {precision}")
print(f"Recall: {recall}")

cm = confusion_matrix(y_test_encoded.argmax(axis=1), y_pred_encoded.argmax(axis=1))
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(mlb.classes_))
plt.xticks(tick_marks, mlb.classes_, rotation=90)
plt.yticks(tick_marks, mlb.classes_)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

# Calculate and plot ROC curves and AUC for each class
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(len(mlb.classes_)):
    fpr[i], tpr[i], _ = roc_curve(y_test_encoded[:, i], y_pred_encoded[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(8, 6))
for i in range(len(mlb.classes_)):
    plt.plot(fpr[i], tpr[i], lw=2, label=f'{mlb.classes_[i]} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

"""**Label-wise Accuracies:** These values represent the accuracy of each sentiment label individually. For each sentiment class (e.g., positive, negative, neutral), the classification model achieves the following accuracies:

`Positive Sentiment:` 88.25%

`Negative Sentiment:` 98.20%

`Neutral Sentiment:` 91.00%

**Mean Accuracy: ** The mean accuracy is the average of the label-wise accuracies, and it provides an overall view of how well the model performs across all sentiment classes. In this case, the mean accuracy is approximately 92.48%, indicating that the model is performing well on average.

**Accuracy Rate:** The accuracy rate measures the overall classification accuracy without considering specific labels. An accuracy rate of 79.90% suggests that the majority of the reviews are being correctly classified into their respective sentiment categories.

**Precision:** Precision measures the ratio of true positive predictions to the total positive predictions. A precision of 94.06% for this model suggests that when it predicts a sentiment label (e.g., positive), it is correct 94.06% of the time.

**Recall:** Recall, also known as sensitivity, measures the ratio of true positive predictions to the actual positive instances. A recall of 91.77% indicates that the model is effective at capturing most of the actual positive reviews.
"""

text = " ".join([" ".join(tokens) for tokens in tokens_df['tokens_text']])

wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

# Display the word cloud using matplotlib
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

